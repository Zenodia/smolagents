{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smolagents==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34a094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents.models import OpenAIServerModel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model_id=\"meta/llama-3.1-405b-instruct\"\n",
    "\n",
    "base_url = 'https://integrate.api.nvidia.com/v1'\n",
    "api_key=os.environ[\"NVIDIA_API_KEY\"]\n",
    "model=OpenAIServerModel(model_id=model_id,\n",
    "        api_base=base_url,\n",
    "        api_key=os.environ[\"NVIDIA_API_KEY\"],\n",
    "        temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951906b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain import prompts, chat_models, hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import Optional, List\n",
    "\n",
    "## construct the system prompt \n",
    "llm= ChatNVIDIA(model=model_id, api_key=api_key, temperature=0.1)\n",
    "def extract_github_issues(user_query):\n",
    "    prompt_template = \"\"\"\n",
    "    ### [INST]\n",
    "\n",
    "    You are an expert on extracting information to search on github issues per given user input query\n",
    "    user query\n",
    "    ------\n",
    "    {user_query}\n",
    "    ------\n",
    "\n",
    "    The output promotion message MUST use the following format :\n",
    "\n",
    "    '''\n",
    "    status: whether the github issue is open or closed, if not specify, then use all\n",
    "    keywords: extracting keywords which could potentailly be used to search on github issues\n",
    "    '''\n",
    "    Begin!\n",
    "    [/INST]\n",
    "     \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "    input_variables=['user_query'],\n",
    "    template=prompt_template)\n",
    "\n",
    "    ## structural output using LMFE \n",
    "    class ExtractIssues(BaseModel):     \n",
    "        status: str = Field(description=\"extract the github issue status, whether it is open or closed from input user query\")\n",
    "        keywords : str = Field(description=\"extract the keywords which users could potentially used to search on github issues\")\n",
    "\n",
    "    extract_github_issues=llm.with_structured_output(ExtractIssues)     \n",
    "\n",
    "    ## construct the content_creator agent\n",
    "    content_creator = ( prompt | extract_github_issues )\n",
    "    out=content_creator.invoke({\"user_query\":user_query})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bd0be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpubootcamp\n",
      "megatron2\n",
      "A100TF2\n",
      "ActiveLearning_exp\n",
      "ADAS\n",
      "Agentless\n",
      "Agent_and_Graph\n",
      "AITrials\n",
      "apex_amp_DALI\n",
      "Applied-Machine-Learning\n",
      "ASR_covid\n",
      "autoKeras\n",
      "Azure\n",
      "azure-quickstart-templates\n",
      "azure-rm-vm\n",
      "BERT_QnA_maker\n",
      "bloomfilter-rb\n",
      "capsule-networks\n",
      "char-rnn\n",
      "Coswara-Data\n",
      "CycleGans\n",
      "datasciencecoursera\n",
      "datasharing\n",
      "deepsort_modified\n",
      "demo_customNMT\n",
      "dlib\n",
      "DockerExp\n",
      "dreamgaussian\n",
      "dspy\n",
      "example-models\n",
      "fastai\n",
      "genai_langserve_apple\n",
      "GenerativeAIExamples\n",
      "gpubootcamp\n",
      "hackathon\n",
      "HF_KBbert_Classification\n",
      "HF_TRL_LORA\n",
      "HybridAGI\n",
      "ImageAI\n",
      "Intro\n",
      "Janus\n",
      "jupyter-ai-agent\n",
      "keras\n",
      "Keras_bbox_regressor\n",
      "kivycrashcourse\n",
      "langchain\n",
      "langgraphstudio_zcharpy\n",
      "langserve\n",
      "LearnAI-Bootcamp\n",
      "learnopencv\n",
      "learn_Cuda\n",
      "machine_learning_examples\n",
      "MakeYourOwnCoCoDataset\n",
      "Megatron-LM\n",
      "MelanomaWebApp\n",
      "mem0\n",
      "MinHash\n",
      "mini_projects\n",
      "MLOps_LengthOfStay\n",
      "MLOps_Pneumonia\n",
      "MMDS\n",
      "moatless-tree-search\n",
      "MOE\n",
      "nativePytorch_NMT\n",
      "NeMo\n",
      "NeMo-Aligner\n",
      "NeMo-Megatron-Launcher\n",
      "NeMo_ASR_TransferLearning_Swedish\n",
      "neural-networks\n",
      "neural-networks-and-deep-learning\n",
      "NGC_exp\n",
      "NLP_Bert_Pytorch_NER_task\n",
      "NLP_multiple_choices_QA\n",
      "NLP_se2en\n",
      "notebook_pics\n",
      "nvidia_nc6_tryout\n",
      "NVmegatron2\n",
      "OpenHands\n",
      "ParkinsonDetectionApp\n",
      "Principles-Of-Machine-Learning\n",
      "Profiler_DLprof_TF1\n",
      "Python\n",
      "python-docs-hello-world\n",
      "pytorch\n",
      "Pytorch_ASR_from_scratch\n",
      "PyTorch_DeepLearning\n",
      "R\n",
      "rapidsai\n",
      "restricted-boltzmann-machines\n",
      "rtsne\n",
      "R_code\n",
      "semantic-kernel\n",
      "SimilarityLayerWised_TRT_before_vs_after\n",
      "simple-neural-network\n",
      "sklearn_pydata2015\n",
      "smolagents\n",
      "stanfordNLP\n",
      "supersmoother\n",
      "swarm\n",
      "Techdays\n",
      "tensorflow\n",
      "TensorRT7\n",
      "TensorRT7_with_custom_layers\n",
      "TF115_A100\n",
      "TF2.4_strategy_hvd\n",
      "TF2_DALI_workshop\n",
      "TF2_exp\n",
      "tf2_keras_hvd\n",
      "TF2_QAT\n",
      "TF2_with_keras\n",
      "TF2_Workshop\n",
      "tiff_image_processing\n",
      "TransferLearning\n",
      "Triton_Pytorch_multimodels_cuda11\n",
      "Triton_TF2_multimodel_CUDA11\n",
      "trl_lora\n",
      "trulens\n",
      "VehiclePlatesDetection\n",
      "VGR_ECG\n",
      "zAzureToolkit\n"
     ]
    }
   ],
   "source": [
    "for repo in token.get_user().get_repos():\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9fe6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "from langchain.docstore.document import Document\n",
    "token = Github(os.environ[\"GITHUB_TOKEN\"])\n",
    "\n",
    "repo = token.get_repo('NVIDIA/NeMo-Guardrails')\n",
    "user_query=\"how to install annoy on windows\"\n",
    "#out=extract_github_issues(user_query)\n",
    "#status=out.status\n",
    "#query=out.keywords\n",
    "\n",
    "open_issues=[]\n",
    "issue_cnt=0\n",
    "            \n",
    "\n",
    "for issue in repo.get_issues(state='open'):\n",
    "    comment_in_same_issue=[]\n",
    "    metadata={'issue_nr':issue_cnt, \"status\":\"open\", \"repo\":\"NVIDIA/NeMo-Guardrails\"}\n",
    "    for comment in issue.get_comments():\n",
    "        \n",
    "        comment_text=comment.body.encode(\"utf-8\")\n",
    "        if len(comment_text)>=1:\n",
    "            doc=Document(page_content=comment_text, metadata=metadata)\n",
    "            open_issues.append(doc)\n",
    "    issue_cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5980dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'issue_nr': 6, 'status': 'open', 'repo': 'NVIDIA/NeMo-Guardrails'}, page_content=\"Hi @Pouyanpi, thanks a lot for your response. I've created a gist [here](https://gist.github.com/ta-dr0aid/1fc2e2f7469ec1452d962cf6244f962a) and included the setup for the local ollama environment. Outputs and steps to reproduce are added as well. \")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_issues[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf187f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e13e94e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:00<00:00, 599.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from smolagents import LiteLLMModel, Tool\n",
    "from smolagents.agents import CodeAgent\n",
    "from smolagents.agents import ToolCallingAgent\n",
    "\n",
    "\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train[:5%]\",)\n",
    "\n",
    "\n",
    "\n",
    "## For your own PDFs, you can use the following code to load them into source_docs\n",
    "# pdf_directory = \"pdfs\"\n",
    "# pdf_files = [\n",
    "#     os.path.join(pdf_directory, f)\n",
    "#     for f in os.listdir(pdf_directory)\n",
    "#     if f.endswith(\".pdf\")\n",
    "# ]\n",
    "# source_docs = []\n",
    "\n",
    "# for file_path in pdf_files:\n",
    "#     loader = PyPDFLoader(file_path)\n",
    "#     docs.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\"thenlper/gte-small\"),\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "# Split docs and keep only unique ones\n",
    "print(\"Splitting documents...\")\n",
    "docs_processed = []\n",
    "unique_texts = {}\n",
    "for doc in tqdm(open_issues):\n",
    "    new_docs = text_splitter.split_documents([doc])\n",
    "    for new_doc in new_docs:\n",
    "        if new_doc.page_content not in unique_texts:\n",
    "            unique_texts[new_doc.page_content] = True\n",
    "            docs_processed.append(new_doc)\n",
    "\n",
    "\n",
    "print(\"Embedding documents... This should take a few minutes (5 minutes on MacBook with M1 Pro)\")\n",
    "# Initialize embeddings and ChromaDB vector store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store = Chroma.from_documents(docs_processed, embeddings, persist_directory=\"./chroma_db\")\n",
    "\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = (\n",
    "        \"Uses semantic search to retrieve the parts of documentation that could be most relevant to answer your query.\"\n",
    "    )\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, vector_store, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vector_store = vector_store\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "        docs = self.vector_store.similarity_search(query, k=3)\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
    "        )\n",
    "\n",
    "\n",
    "retriever_tool = RetrieverTool(vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e24dec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Windows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)\\n\\nLinux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)\\n\\n===== Document 1 =====\\nWindows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)\\n\\nLinux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)\\n\\n===== Document 2 =====\\nWindows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)\\n\\nLinux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)',\n",
       " 'Windows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)\\n\\nLinux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)\\n\\n===== Document 2 =====\\nWindows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)\\n\\nLinux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)',\n",
       " 'Windows: Download [this executable](https://drive.google.com/file/d/1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP/view?usp=sharing)\\n\\nLinux (Ubuntu): Download [this executable](https://drive.google.com/file/d/1KuqBKYiXiIcU4kNMqEzhgypuFP5_45CL/view?usp=sharing)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=retriever_tool.forward(\"how do i install annoy on windows \")\n",
    "[out.split(f\"\\n\\n===== Document {str(i)} =====\\n\")[1] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c89c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8357ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">how do i register a custom action?</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - meta/llama-3.1-405b-instruct ──────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mhow do i register a custom action?\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - meta/llama-3.1-405b-instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing this code:</span> ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">result </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"registering custom actions\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(result)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting this code:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mresult\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mregistering custom actions\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresult\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "\n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Thanks for that, I understand how to register custom actions itself but they don't work when I'm trying to launch \n",
       "them on the server UI. \n",
       "\n",
       "Any help on that part?\n",
       "\n",
       "Currently this is my actions.py file:\n",
       "```\n",
       "import os\n",
       "from typing import Any, List, Optional\n",
       "\n",
       "from nemoguardrails.actions import action\n",
       "from nemoguardrails import LLMRails\n",
       "\n",
       "\n",
       "@action()\n",
       "async def block_list(file_name: Optional[str] = None, context: Optional[dict] = None):\n",
       "    bot_response = context.get(\"last_bot_message\")\n",
       "\n",
       "===== Document 1 =====\n",
       "Thanks for pointing this @joeywhelan! Indeed, we should update the docs. \n",
       "You have to declare a parameter for your action which has exactly the same name as the one you registered.\n",
       "\n",
       "===== Document 2 =====\n",
       "Hey @florence26\n",
       "\n",
       "Custom actions can be registered with:\n",
       "\n",
       "1. LLMRails.register_action\n",
       "2. action() decorator imported from nemoguardrails.actions.actions\n",
       "\n",
       "You can use it as follow:\n",
       "```\n",
       "from nemoguardrails import LLMRails, RailsConfig\n",
       "from dotenv import load_dotenv\n",
       "import logging\n",
       "logging.basicConfig(level=\"INFO\")\n",
       "\n",
       "load_dotenv()\n",
       "\n",
       "YAML_CONFIG = \"\"\"\n",
       "models:\n",
       "  - type: main\n",
       "    engine: openai\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "\n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Thanks for that, I understand how to register custom actions itself but they don't work when I'm trying to launch \n",
       "them on the server UI. \n",
       "\n",
       "Any help on that part?\n",
       "\n",
       "Currently this is my actions.py file:\n",
       "```\n",
       "import os\n",
       "from typing import Any, List, Optional\n",
       "\n",
       "from nemoguardrails.actions import action\n",
       "from nemoguardrails import LLMRails\n",
       "\n",
       "\n",
       "@action()\n",
       "async def block_list(file_name: Optional[str] = None, context: Optional[dict] = None):\n",
       "    bot_response = context.get(\"last_bot_message\")\n",
       "\n",
       "===== Document 1 =====\n",
       "Thanks for pointing this @joeywhelan! Indeed, we should update the docs. \n",
       "You have to declare a parameter for your action which has exactly the same name as the one you registered.\n",
       "\n",
       "===== Document 2 =====\n",
       "Hey @florence26\n",
       "\n",
       "Custom actions can be registered with:\n",
       "\n",
       "1. LLMRails.register_action\n",
       "2. action() decorator imported from nemoguardrails.actions.actions\n",
       "\n",
       "You can use it as follow:\n",
       "```\n",
       "from nemoguardrails import LLMRails, RailsConfig\n",
       "from dotenv import load_dotenv\n",
       "import logging\n",
       "logging.basicConfig(level=\"INFO\")\n",
       "\n",
       "load_dotenv()\n",
       "\n",
       "YAML_CONFIG = \"\"\"\n",
       "models:\n",
       "  - type: main\n",
       "    engine: openai\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 14.91 seconds| Input tokens: 2,049 | Output tokens: 63]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 14.91 seconds| Input tokens: 2,049 | Output tokens: 63]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing this code:</span> ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"You can register custom actions using LLMRails.register_action or the @action() decorator from </span><span style=\"background-color: #272822\">  </span>  \n",
       "  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">nemoguardrails.actions.actions. Make sure to declare a parameter with the same name as the registered action.\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting this code:\u001b[0m ────────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mYou can register custom actions using LLMRails.register_action or the @action() decorator from \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m  \n",
       "  \u001b[38;2;230;219;116;48;2;39;40;34mnemoguardrails.actions.actions. Make sure to declare a parameter with the same name as the registered action.\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: You can register custom actions using LLMRails.register_action or the @action() decorator from </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">nemoguardrails.actions.actions. Make sure to declare a parameter with the same name as the registered action.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: You can register custom actions using LLMRails.register_action or the @action() decorator from \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mnemoguardrails.actions.actions. Make sure to declare a parameter with the same name as the registered action.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.70 seconds| Input tokens: 4,509 | Output tokens: 150]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.70 seconds| Input tokens: 4,509 | Output tokens: 150]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from  smolagents import Tool\n",
    "from smolagents import ToolCallingAgent\n",
    "from smolagents.models import OpenAIServerModel\n",
    "\n",
    "model=OpenAIServerModel(model_id=model_id,\n",
    "        api_base=base_url,\n",
    "        api_key=os.environ[\"NVIDIA_API_KEY\"],\n",
    "        temperature=0.1)\n",
    "\n",
    "#agent = ToolCallingAgent( tools=[retriever_tool], model=model)\n",
    "agent = CodeAgent(tools=[retriever_tool], model=model, add_base_tools=False)\n",
    " \n",
    "agent_output = agent.run(\"how do i register a custom action? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7922ae44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can register custom actions using LLMRails.register_action or the @action() decorator from nemoguardrails.actions.actions. Make sure to declare a parameter with the same name as the registered action.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
